{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lje0LaD8Ptpw"
   },
   "source": [
    "# entropía y unimorph!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = open(\"datos/shp\", \"r\")\n",
    "#lemas = list(zip(*[line.split() for line in f]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = open(\"datos/shp\", \"r\")\n",
    "#inflexiones = list(zip(*[line.split() for line in f]))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = open(\"datos/shp\", \"r\")\n",
    "#codes = list(zip(*[line.split() for line in f]))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemas = [lemas[i] for i in range(len(lemas)) if i not in [4820,4821]]\n",
    "#inflexiones = [inflexiones[i] for i in range(len(inflexiones)) if i not in [4820,4821]]\n",
    "#codes = [codes[i] for i in range(len(codes)) if i not in [4820,4821]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shp = {'formas':lemas, 'inflexiones': inflexiones, 'codes':codes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datos = pd.DataFrame.from_dict(shp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://github.com/unimorph/que\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "lengua = 'cni' ## (puede ser, dak, arn, cni, aym, mao y que)\n",
    "datos = pd.read_csv('datos/'+lengua, sep='\\t', header=None)\n",
    "datos.columns = ['formas','inflexiones','codes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "## solo los verbos\n",
    "\n",
    "datos = datos[datos['codes'].str.startswith('V')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "## nos quedamos solo con formas e inflexiones\n",
    "\n",
    "datos = datos[['formas', 'inflexiones']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formas</th>\n",
       "      <th>inflexiones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aabintaantsi</td>\n",
       "      <td>aabintaantsi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aabintaantsi</td>\n",
       "      <td>aabintaje</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aabintaantsi</td>\n",
       "      <td>aabintaje</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aabintaantsi</td>\n",
       "      <td>aabintaji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aabintaantsi</td>\n",
       "      <td>aabintaji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20065</th>\n",
       "      <td>yotaantsi</td>\n",
       "      <td>piyotake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20066</th>\n",
       "      <td>yotaantsi</td>\n",
       "      <td>piyotake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20067</th>\n",
       "      <td>yotaantsi</td>\n",
       "      <td>piyote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20068</th>\n",
       "      <td>yotaantsi</td>\n",
       "      <td>piyoti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20069</th>\n",
       "      <td>yotaantsi</td>\n",
       "      <td>yotaantsi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5622 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             formas   inflexiones\n",
       "0      aabintaantsi  aabintaantsi\n",
       "1      aabintaantsi     aabintaje\n",
       "2      aabintaantsi     aabintaje\n",
       "3      aabintaantsi     aabintaji\n",
       "4      aabintaantsi     aabintaji\n",
       "...             ...           ...\n",
       "20065     yotaantsi      piyotake\n",
       "20066     yotaantsi      piyotake\n",
       "20067     yotaantsi        piyote\n",
       "20068     yotaantsi        piyoti\n",
       "20069     yotaantsi     yotaantsi\n",
       "\n",
       "[5622 rows x 2 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemas = list(datos['formas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "inflexiones = list(datos['inflexiones'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5622\n"
     ]
    }
   ],
   "source": [
    "print(len(lemas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Primero, definimos una lista de lemas únicos\n",
    "\n",
    "lemas_unicos = []\n",
    "\n",
    "## recorremos la lista de lemas\n",
    "for lema in lemas:\n",
    "    ## solo agregamos si no está en lemas_unicos\n",
    "    if lema not in lemas_unicos:\n",
    "        lemas_unicos+=[lema]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "## definimos un diccionario vacío\n",
    "\n",
    "D_lema_inflex = {}\n",
    "\n",
    "## recorremos la lista de lemas_unicos\n",
    "for lema in lemas_unicos:\n",
    "    ## agregamos en cada iteración, una lista vacía :)\n",
    "    D_lema_inflex[lema]=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "## recorremos la lista de lemas (la original). Usamos los índices!\n",
    "\n",
    "for i in range(len(lemas)):\n",
    "    ## accedemos al lema de la posición i\n",
    "    lema = lemas[i]\n",
    "    ## guardamos en la lista asociada las inflexiones del lema (que están en la lista inflexiones)\n",
    "    D_lema_inflex[lema]+=[inflexiones[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(D_lema_inflex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## muestreo de lemas/inflexiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "lista_lemas = []\n",
    "lista_inflexiones = []\n",
    "\n",
    "s = 100\n",
    "for r in range(100):\n",
    "    n = len(D_lema_inflex)\n",
    "    if n < s:\n",
    "        indexes = random.sample(list(range(len(D_lema_inflex.keys()))),n)\n",
    "    else:\n",
    "        indexes = random.sample(list(range(len(D_lema_inflex.keys()))),s)\n",
    "    lemas = [list(D_lema_inflex.keys())[i] for i in indexes]\n",
    "    inflexiones = []\n",
    "    for l in lemas:\n",
    "        inflexiones += D_lema_inflex[l]\n",
    "    lista_lemas += [lemas]\n",
    "    lista_inflexiones += [inflexiones]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## entropías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_strings = []\n",
    "\n",
    "for i in range(len(lista_lemas)):\n",
    "    \n",
    "    ## lemas/inflexiones\n",
    "    lemas = lista_lemas[i]\n",
    "    inflexiones = lista_inflexiones[i]\n",
    "    \n",
    "    STRINGS = {'lemas': [], 'inflexiones': []}\n",
    "    lem = ['#'+s+'$' for s in lemas]\n",
    "    inf = ['#'+s+'$' for s in inflexiones]\n",
    "    STRINGS['lemas'] = lem\n",
    "    STRINGS['inflexiones'] = inf\n",
    "    lista_strings += [STRINGS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ngrams(input_list, n):\n",
    "    return [''.join(tup) for tup in list(zip(*[input_list[i:] for i in range(n)]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#ac',\n",
       " 'ach',\n",
       " 'cha',\n",
       " 'hal',\n",
       " 'ala',\n",
       " 'lac',\n",
       " 'ach',\n",
       " 'chi',\n",
       " 'hic',\n",
       " 'ich',\n",
       " 'chu',\n",
       " 'hun',\n",
       " 'unk',\n",
       " 'nku',\n",
       " 'ku$']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_ngrams('#achalachichunku$',3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_ngramas = []\n",
    "\n",
    "for item in lista_strings:\n",
    "    \n",
    "    STRINGS = item\n",
    "    \n",
    "    NGRAMAS = {'lemas': [], 'inflexiones': []}\n",
    "\n",
    "    for w in STRINGS['lemas']:\n",
    "        NGRAMAS['lemas']+=find_ngrams(w,3)\n",
    "    \n",
    "    for w in STRINGS['inflexiones']:\n",
    "        NGRAMAS['inflexiones']+=find_ngrams(w,3)\n",
    "    lista_ngramas += [NGRAMAS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from scipy.stats import entropy\n",
    "import math\n",
    "\n",
    "lista_entropias = []\n",
    "\n",
    "for item in lista_ngramas:\n",
    "    NGRAMAS = item\n",
    "    entropias = {}\n",
    "\n",
    "    for key in NGRAMAS.keys():\n",
    "        C = list(dict(Counter(NGRAMAS[key])).values())\n",
    "        H = entropy(C,base = sum(C))\n",
    "        entropias[key] = H\n",
    "    lista_entropias += [entropias]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "lista_entropias_lemas_mean = np.mean([D['lemas'] for D in lista_entropias])\n",
    "lista_entropias_lemas_std = np.std([D['lemas'] for D in lista_entropias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5963378998546542, 0.003964256921982297)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_entropias_lemas_mean, lista_entropias_lemas_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_entropias_inflex_mean = np.mean([D['inflexiones'] for D in lista_entropias])\n",
    "lista_entropias_inflex_std = np.std([D['inflexiones'] for D in lista_entropias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5177060389196284, 0.0024123925490850736)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_entropias_inflex_mean, lista_entropias_inflex_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07863186093502583"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_entropias_lemas_mean - lista_entropias_inflex_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['aabintaantsi', 'aantsi', 'abinata', 'abisaantsi', 'abitsanotaantsi', 'ajirikaantsi', 'akishitaantsi', 'amaantsi', 'amaataantsi', 'amajataantsi', 'amashaetaanti', 'amenaantsi', 'ametaantsi', 'amitakotaantsi', 'ampitsataantsi', 'aneenkaantsi', 'aniibeetaantsi', 'aniitaantsi', 'antaantsi', 'antabeetaantsi', 'antanataantsi', 'apajirikaantsi', 'apatotaantsi', 'apiitaantsi', 'araantsi', 'areetaantsi', 'asaankaantsi', 'asankaantsi', 'ashirejaantsi', 'ashitaantsi', 'ashitareantsi', 'ataitaantsi', 'atisankaantsi', 'atsikaantsi', 'atsipetaantsi', 'atsokijaantsi', 'atsotaantsi', 'bametaantsi', 'batsataantsi', 'betakaantsi', 'betsataantsi', 'betsikaantsi', 'chekaantsi', 'intaantsi', 'iraantsi', 'jaantsi', 'jataantsi', 'jibataantsi', 'jikotaantsi', 'jimatsitaantsi', 'jirotaantsi', 'kaataantsi', 'kabichoaantsi', 'kajataantsi', 'kajemaantsi', 'kamantaantsi', 'kametojaantsi', 'kantaantsi', 'karajaantsi', 'katiaantsi', 'katinkaantsi', 'katsiinkataantsi', 'kemaantsi', 'kemityonkaantsi', 'kempetaantsi', 'kenkeshireaantsi', 'kenketsashireaanti', 'kerojaantsi', 'kibaantsi', 'kichojaantsi', 'kirikaantsi', 'kisaantsi', 'kitsataantsi', 'kobaantsi', 'kobintsaantsi', 'komitaantsi', 'koshitaantsi', 'maantsi', 'makoreaantsi', 'manaantsi', 'mantsiataantsi', 'mapokaantsi', 'matikaantsi', 'mijaantsi', 'mishitaantsi', 'ñaantsi', 'nebetaantsi', 'ninataants', 'nintaantsi', 'nojataantsi', 'noshikaantsi', 'oaantsi', 'oijataantsi', 'oimajataantsi', 'oipakaantsi', 'oisaantaantsi', 'okireaantsi', 'onkojataantsi', 'pajitaantsi', 'pankitaantsi', 'pasabakotaantsi', 'pasekataantsi', 'pashitaantsi', 'pesaantsi', 'piaantsi', 'piinkaantsi', 'pimantaantsi', 'pinataantsi', 'pioreaantsi', 'piotaantsi', 'pitsitaantsi', 'poataantsi', 'pokaantsi', 'posaantsi', 'potetaantsi', 'potsotaantsi', 'saakitaantsi', 'saankaantsi', 'saboreantsi', 'saikaantsi', 'saitaantsi', 'sakotaantsi', 'sampitaantsi', 'sankenataantsi', 'sapokaantsi', 'shetaantsi', 'shiaantsi', 'shiakotaantsi', 'shimataantsi', 'shinkitaantsi', 'shiokaantsi', 'shirontaantsi', 'shitikaantsi', 'shititaantsi', 'taantsi', 'takireaantsi', 'tatsinkaantsi', 'tiankaantsi', 'tijaantsi', 'totaantsi', 'tsameetantsi', 'tsarotaantsi', 'tsentetaantsi', 'tsimankaantsi', 'tsinakaantsi', 'tsintaantsi', 'tsipataantsi', 'tsokijaantsi', 'yentitaantsi', 'yotaantsi'])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_lema_inflex.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_4uYLPGXPtq0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "clase-2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
